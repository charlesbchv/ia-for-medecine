{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "marked": true
        },
        "id": "zyo-3pxyQyue"
      },
      "source": [
        "# Compare Perform PCA and LDA & CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzgXfJIBQyug"
      },
      "source": [
        "# Install and import relevant libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BRapgAEYQyug"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAQRuh3hQyuh"
      },
      "source": [
        "# Load Data for PCA and LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6y7HAHgHQyuh"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"stand_norm_e1.txt\", delimiter='\\s+')\n",
        "new_values = pd.read_csv(\"y2_e1.txt\", header=None, names=['New_Class'], delimiter='\\s+')\n",
        "df['Class'] = new_values['New_Class']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA2pkoDJQyui"
      },
      "source": [
        "# Load Data for CNN with 2 dataset concatenated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "YREdcn9hQyui"
      },
      "outputs": [],
      "source": [
        "dataset_e1 = pd.read_csv(\"stand_norm_e1.txt\", delimiter='\\s+')\n",
        "dataset_e2 = pd.read_csv(\"stand_norm_e2.txt\", delimiter='\\s+')\n",
        "dataset = pd.concat([dataset_e1, dataset_e2], axis=0)\n",
        "#dataset = pd.read_csv(\"stand_norm_e1.txt\", delimiter='\\s+')\n",
        "new_values = pd.read_csv(\"y2_e1.txt\", header=None, names=['New_Class'], delimiter='\\s+')\n",
        "dataset['Class'] = new_values['New_Class']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MCobzsKQyuj"
      },
      "source": [
        "# Split Data into Features and Target variable for PCA and LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "gKMZB3UjQyuj"
      },
      "outputs": [],
      "source": [
        "X_pca_lda = df.drop('Class', axis=1)\n",
        "y_pca_lda = df['Class']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rAnCzX9Qyuk"
      },
      "source": [
        "# Split Data for CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "cnDStDA7Qyul"
      },
      "outputs": [],
      "source": [
        "X_cnn = dataset.iloc[:, 1:5].values\n",
        "y_cnn = dataset['Class'].values\n",
        "le = LabelEncoder()\n",
        "y_cnn_encoded = le.fit_transform(y_cnn)\n",
        "y_cnn_encoded = tf.keras.utils.to_categorical(y_cnn_encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Edm5uRFnQyul"
      },
      "source": [
        "# Standardize Features for PCA and LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "qYLZmyd8Qyul"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled_pca_lda = scaler.fit_transform(X_pca_lda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArErWwePQyum"
      },
      "source": [
        "# Split Data into Training and Testing sets for PCA and LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "gOQ336cCQyum"
      },
      "outputs": [],
      "source": [
        "X_train_pca_lda, X_test_pca_lda, y_train_pca_lda, y_test_pca_lda = train_test_split(X_scaled_pca_lda, y_pca_lda, test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boRQm02YQyum"
      },
      "source": [
        "# Split Data into Training and Testing sets for CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "LUnZ_kBjQyum"
      },
      "outputs": [],
      "source": [
        "X_train_cnn, X_test_cnn, y_train_cnn, y_test_cnn = train_test_split(X_cnn, y_cnn_encoded, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om9n1HYSQyum"
      },
      "source": [
        "# Define CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPqly-mAQyun",
        "outputId": "d9949151-f9c2-4f8e-fd73-ada6351174f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1025/1025 [==============================] - 6s 5ms/step - loss: 2.2767 - accuracy: 0.7521\n",
            "Epoch 2/20\n",
            "1025/1025 [==============================] - 3s 3ms/step - loss: 0.5955 - accuracy: 0.7791\n",
            "Epoch 3/20\n",
            "1025/1025 [==============================] - 3s 3ms/step - loss: 0.5602 - accuracy: 0.7809\n",
            "Epoch 4/20\n",
            "1025/1025 [==============================] - 5s 5ms/step - loss: 0.5490 - accuracy: 0.7825\n",
            "Epoch 5/20\n",
            "1025/1025 [==============================] - 4s 3ms/step - loss: 0.5399 - accuracy: 0.7807\n",
            "Epoch 6/20\n",
            "1025/1025 [==============================] - 4s 3ms/step - loss: 0.5337 - accuracy: 0.7806\n",
            "Epoch 7/20\n",
            "1025/1025 [==============================] - 4s 4ms/step - loss: 0.5408 - accuracy: 0.7824\n",
            "Epoch 8/20\n",
            "1025/1025 [==============================] - 4s 4ms/step - loss: 0.5317 - accuracy: 0.7824\n",
            "Epoch 9/20\n",
            "1025/1025 [==============================] - 3s 3ms/step - loss: 0.5320 - accuracy: 0.7817\n",
            "Epoch 10/20\n",
            "1025/1025 [==============================] - 3s 3ms/step - loss: 0.5449 - accuracy: 0.7817\n",
            "Epoch 11/20\n",
            "1025/1025 [==============================] - 4s 4ms/step - loss: 0.5359 - accuracy: 0.7829\n",
            "Epoch 12/20\n",
            "1025/1025 [==============================] - 4s 4ms/step - loss: 0.5358 - accuracy: 0.7829\n",
            "Epoch 13/20\n",
            "1025/1025 [==============================] - 3s 3ms/step - loss: 0.5359 - accuracy: 0.7829\n",
            "Epoch 14/20\n",
            "1025/1025 [==============================] - 3s 3ms/step - loss: 0.5358 - accuracy: 0.7829\n",
            "Epoch 15/20\n",
            "1025/1025 [==============================] - 4s 4ms/step - loss: 0.5358 - accuracy: 0.7829\n",
            "Epoch 16/20\n",
            "1025/1025 [==============================] - 4s 3ms/step - loss: 0.5358 - accuracy: 0.7829\n",
            "Epoch 17/20\n",
            "1025/1025 [==============================] - 3s 3ms/step - loss: 0.5358 - accuracy: 0.7829\n",
            "Epoch 18/20\n",
            "1025/1025 [==============================] - 3s 3ms/step - loss: 0.5358 - accuracy: 0.7829\n",
            "Epoch 19/20\n",
            "1025/1025 [==============================] - 5s 5ms/step - loss: 0.5358 - accuracy: 0.7829\n",
            "Epoch 20/20\n",
            "1025/1025 [==============================] - 3s 3ms/step - loss: 0.5358 - accuracy: 0.7829\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a63d4e8f040>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(filters=128, kernel_size=3, activation='relu', padding='same', input_shape=(X_train_cnn.shape[1], 1)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(y_train_cnn.shape[1], activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_cnn, y_train_cnn, epochs=20, batch_size=20, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0ycxwl5Qyun"
      },
      "source": [
        "# Define PCA Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "QuyLrqwpQyun"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=2)\n",
        "X_train_pca = pca.fit_transform(X_train_pca_lda)\n",
        "X_test_pca = pca.transform(X_test_pca_lda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNzwPkkLQyun"
      },
      "source": [
        "# Define LDA Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "AY1nvxveQyuo"
      },
      "outputs": [],
      "source": [
        "lda = LinearDiscriminantAnalysis(n_components=2)\n",
        "X_train_lda = lda.fit_transform(X_train_pca_lda, y_train_pca_lda)\n",
        "X_test_lda = lda.transform(X_test_pca_lda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg3Work1Qyuo"
      },
      "source": [
        "# Evaluate Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "eTfn6du2Qyuo"
      },
      "outputs": [],
      "source": [
        "pca_score = accuracy_score(y_test_pca_lda, lda.predict(X_test_pca_lda))\n",
        "lda_score = accuracy_score(y_test_pca_lda, lda.predict(X_test_pca_lda))\n",
        "cnn_loss, cnn_accuracy = model.evaluate(X_test_cnn, y_test_cnn, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgY5yPaHQyuo"
      },
      "source": [
        "# Compare Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpxZmAZKQyuo",
        "outputId": "bd61b078-ac35-4ffc-b945-4678767df1b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN performs the best with an accuracy of 77.91%\n"
          ]
        }
      ],
      "source": [
        "if pca_score > lda_score and pca_score > cnn_accuracy:\n",
        "    print(\"PCA performs the best with a score of {:.2f}\".format(pca_score))\n",
        "elif lda_score > pca_score and lda_score > cnn_accuracy:\n",
        "    print(\"LDA performs the best with a score of {:.2f}\".format(lda_score))\n",
        "else:\n",
        "    print(\"CNN performs the best with an accuracy of {:.2f}%\".format(cnn_accuracy*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lors de la concaténation des deux ensembles de données, à savoir stand_norm_e1 et *stand_norm_e2*, nous observons une diminution des performances, avec une précision maximale obtenue par le réseau de neurones convolutifs (CNN) de **77,91 %**. En revanche, lorsque le premier ensemble de données stand_norm_e1 est utilisé isolément, la performance du CNN s'améliore, atteignant une précision de **78,81 %.**"
      ],
      "metadata": {
        "id": "Or3emh62TD0_"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}