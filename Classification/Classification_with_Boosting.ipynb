{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLaebpXyqqUr"
      },
      "source": [
        "# Classic classification algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDqYjKwDqqUw"
      },
      "source": [
        "We are going to classify our datasets using multiple classification algorithms and evaluate their performances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTL6llluqqUy",
        "outputId": "92d106cf-b41e-4fd8-ab1f-75daf6512129"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scikit-learn==1.2.2 is not installed. Installing...\n",
            "Requirement already satisfied: scikit-learn==1.2.2 in c:\\users\\elodie\\desktop\\esiee\\ia\\projet annuel\\ia-for-medecine\\.venv\\lib\\site-packages (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\elodie\\desktop\\esiee\\ia\\projet annuel\\ia-for-medecine\\.venv\\lib\\site-packages (from scikit-learn==1.2.2) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\elodie\\desktop\\esiee\\ia\\projet annuel\\ia-for-medecine\\.venv\\lib\\site-packages (from scikit-learn==1.2.2) (1.26.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\elodie\\desktop\\esiee\\ia\\projet annuel\\ia-for-medecine\\.venv\\lib\\site-packages (from scikit-learn==1.2.2) (3.5.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\elodie\\desktop\\esiee\\ia\\projet annuel\\ia-for-medecine\\.venv\\lib\\site-packages (from scikit-learn==1.2.2) (1.13.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.2.2 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "imblearn is already installed.\n",
            "deslib is not installed. Installing...\n",
            "Collecting deslib\n",
            "  Using cached DESlib-0.3.7-py3-none-any.whl (172 kB)\n",
            "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\elodie\\desktop\\esiee\\ia\\projet annuel\\ia-for-medecine\\.venv\\lib\\site-packages (from deslib) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.4.0 in c:\\users\\elodie\\desktop\\esiee\\ia\\projet annuel\\ia-for-medecine\\.venv\\lib\\site-packages (from deslib) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\elodie\\desktop\\esiee\\ia\\projet annuel\\ia-for-medecine\\.venv\\lib\\site-packages (from deslib) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\elodie\\desktop\\esiee\\ia\\projet annuel\\ia-for-medecine\\.venv\\lib\\site-packages (from scikit-learn>=1.0.2->deslib) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\elodie\\desktop\\esiee\\ia\\projet annuel\\ia-for-medecine\\.venv\\lib\\site-packages (from scikit-learn>=1.0.2->deslib) (3.5.0)\n",
            "Installing collected packages: deslib\n",
            "Successfully installed deslib-0.3.7\n",
            "joblib==1.4.2 is not installed. Installing...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.2.2 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: joblib==1.4.2 in c:\\users\\elodie\\desktop\\esiee\\ia\\projet annuel\\ia-for-medecine\\.venv\\lib\\site-packages (1.4.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.2.2 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Packages to install\n",
        "packages_to_install = ['scikit-learn==1.2.2', 'imblearn', 'deslib', 'joblib==1.4.2']\n",
        "\n",
        "# Check if they are already installed\n",
        "import importlib\n",
        "for package in packages_to_install:\n",
        "    try:\n",
        "        importlib.import_module(package)\n",
        "        print(f\"{package} is already installed.\")\n",
        "    except ImportError:\n",
        "        print(f\"{package} is not installed. Installing...\")\n",
        "        !pip install {package}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rznrNVCXqqU1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Elodie\\Desktop\\ESIEE\\IA\\PROJET ANNUEL\\ia-for-medecine\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "ressources_path = \"../Ressources/Datasets/\"\n",
        "models_path = \"../Interface/Server/models/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XZ0f-MHqqU2"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "Iwxcot_nqqU3",
        "outputId": "27eaceda-2077-4e0d-b9f7-15c870672569"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>12809.000000</td>\n",
              "      <td>12809.000000</td>\n",
              "      <td>12809.000000</td>\n",
              "      <td>12809.000000</td>\n",
              "      <td>12809.000000</td>\n",
              "      <td>12809.000000</td>\n",
              "      <td>12809.000000</td>\n",
              "      <td>12809.000000</td>\n",
              "      <td>12809.000000</td>\n",
              "      <td>12809.000000</td>\n",
              "      <td>12809.000000</td>\n",
              "      <td>12809.000000</td>\n",
              "      <td>12809.000000</td>\n",
              "      <td>12809.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.715800</td>\n",
              "      <td>105.179340</td>\n",
              "      <td>151.438104</td>\n",
              "      <td>550.188281</td>\n",
              "      <td>1858.821366</td>\n",
              "      <td>0.639516</td>\n",
              "      <td>0.606294</td>\n",
              "      <td>13.894588</td>\n",
              "      <td>151.443231</td>\n",
              "      <td>149.896051</td>\n",
              "      <td>400.836349</td>\n",
              "      <td>1220.861916</td>\n",
              "      <td>0.639516</td>\n",
              "      <td>0.726532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>13.661444</td>\n",
              "      <td>118.380416</td>\n",
              "      <td>198.978664</td>\n",
              "      <td>596.648195</td>\n",
              "      <td>4357.460170</td>\n",
              "      <td>0.298755</td>\n",
              "      <td>0.355149</td>\n",
              "      <td>25.014059</td>\n",
              "      <td>184.578246</td>\n",
              "      <td>182.014356</td>\n",
              "      <td>427.817220</td>\n",
              "      <td>2481.003246</td>\n",
              "      <td>0.298755</td>\n",
              "      <td>0.402590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.004030</td>\n",
              "      <td>0.497232</td>\n",
              "      <td>1.136887</td>\n",
              "      <td>1.550758</td>\n",
              "      <td>2.000634</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009388</td>\n",
              "      <td>0.008162</td>\n",
              "      <td>1.076040</td>\n",
              "      <td>0.955428</td>\n",
              "      <td>3.392103</td>\n",
              "      <td>7.449574</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.651308</td>\n",
              "      <td>28.135965</td>\n",
              "      <td>36.205070</td>\n",
              "      <td>160.794149</td>\n",
              "      <td>572.195981</td>\n",
              "      <td>0.407475</td>\n",
              "      <td>0.324020</td>\n",
              "      <td>0.593510</td>\n",
              "      <td>22.236411</td>\n",
              "      <td>36.182643</td>\n",
              "      <td>125.101548</td>\n",
              "      <td>436.947264</td>\n",
              "      <td>0.407475</td>\n",
              "      <td>0.373920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.563679</td>\n",
              "      <td>73.496119</td>\n",
              "      <td>79.066449</td>\n",
              "      <td>341.937147</td>\n",
              "      <td>1092.008474</td>\n",
              "      <td>0.664512</td>\n",
              "      <td>0.461491</td>\n",
              "      <td>3.255613</td>\n",
              "      <td>83.524212</td>\n",
              "      <td>84.391739</td>\n",
              "      <td>255.453341</td>\n",
              "      <td>768.756167</td>\n",
              "      <td>0.664512</td>\n",
              "      <td>0.567023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>9.841018</td>\n",
              "      <td>145.229559</td>\n",
              "      <td>183.952667</td>\n",
              "      <td>722.194942</td>\n",
              "      <td>2030.703113</td>\n",
              "      <td>0.859797</td>\n",
              "      <td>0.844648</td>\n",
              "      <td>17.586211</td>\n",
              "      <td>223.050740</td>\n",
              "      <td>191.915684</td>\n",
              "      <td>518.186018</td>\n",
              "      <td>1335.167249</td>\n",
              "      <td>0.859797</td>\n",
              "      <td>1.063422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>513.804645</td>\n",
              "      <td>4126.791150</td>\n",
              "      <td>3471.703620</td>\n",
              "      <td>6547.571997</td>\n",
              "      <td>304245.165000</td>\n",
              "      <td>1.932471</td>\n",
              "      <td>1.933941</td>\n",
              "      <td>540.411313</td>\n",
              "      <td>3139.233639</td>\n",
              "      <td>2126.014583</td>\n",
              "      <td>6557.959843</td>\n",
              "      <td>92455.135460</td>\n",
              "      <td>1.932471</td>\n",
              "      <td>1.990678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0             1             2             3              4   \\\n",
              "count  12809.000000  12809.000000  12809.000000  12809.000000   12809.000000   \n",
              "mean       7.715800    105.179340    151.438104    550.188281    1858.821366   \n",
              "std       13.661444    118.380416    198.978664    596.648195    4357.460170   \n",
              "min        0.004030      0.497232      1.136887      1.550758       2.000634   \n",
              "25%        0.651308     28.135965     36.205070    160.794149     572.195981   \n",
              "50%        2.563679     73.496119     79.066449    341.937147    1092.008474   \n",
              "75%        9.841018    145.229559    183.952667    722.194942    2030.703113   \n",
              "max      513.804645   4126.791150   3471.703620   6547.571997  304245.165000   \n",
              "\n",
              "                 5             6             8             9             10  \\\n",
              "count  12809.000000  12809.000000  12809.000000  12809.000000  12809.000000   \n",
              "mean       0.639516      0.606294     13.894588    151.443231    149.896051   \n",
              "std        0.298755      0.355149     25.014059    184.578246    182.014356   \n",
              "min        0.000000      0.009388      0.008162      1.076040      0.955428   \n",
              "25%        0.407475      0.324020      0.593510     22.236411     36.182643   \n",
              "50%        0.664512      0.461491      3.255613     83.524212     84.391739   \n",
              "75%        0.859797      0.844648     17.586211    223.050740    191.915684   \n",
              "max        1.932471      1.933941    540.411313   3139.233639   2126.014583   \n",
              "\n",
              "                 11            12            13            14  \n",
              "count  12809.000000  12809.000000  12809.000000  12809.000000  \n",
              "mean     400.836349   1220.861916      0.639516      0.726532  \n",
              "std      427.817220   2481.003246      0.298755      0.402590  \n",
              "min        3.392103      7.449574      0.000000      0.006647  \n",
              "25%      125.101548    436.947264      0.407475      0.373920  \n",
              "50%      255.453341    768.756167      0.664512      0.567023  \n",
              "75%      518.186018   1335.167249      0.859797      1.063422  \n",
              "max     6557.959843  92455.135460      1.932471      1.990678  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x1 = pd.read_csv(ressources_path + \"stand_norm_e1.txt\", header=None, delimiter=\" \")\n",
        "x2 = pd.read_csv(ressources_path + \"stand_norm_e2.txt\", header=None, delimiter=\" \", names=[8, 9, 10, 11, 12, 13, 14])\n",
        "y = pd.read_csv(ressources_path + \"y2_e1.txt\", header=None, delimiter=\" \", names=[\"label\"])\n",
        "x = pd.concat([x1, x2], axis=1)\n",
        "x = x[1:]\n",
        "y = y[1:]\n",
        "\n",
        "x.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UC9ApHTZqqU5"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset into training and test set.\n",
        "x_train, x_test, y_train, y_test = train_test_split(x.values, y.values, test_size = 0.25, random_state=0)\n",
        "\n",
        "# Feature Scaling\n",
        "# Adjust the mean to 0 and the standard deviation to 1\n",
        "st_x = StandardScaler()\n",
        "x_train = st_x.fit_transform(x_train)\n",
        "x_test = st_x.transform(x_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HeNvu29LqqU6"
      },
      "outputs": [],
      "source": [
        "# Oversample to have same number of samples of each class\n",
        "smote = SMOTE()\n",
        "x_train_sampled, y_train_sampled = smote.fit_resample(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKfDJ2m4qqU8"
      },
      "source": [
        "## Feature extraction : CNN\n",
        "We are going to extract features from the datasets using the CNN method, knowing that it has the best performances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lavZ6T-GqqU-"
      },
      "outputs": [],
      "source": [
        "# Vérification et reformattage de y_train_sampled pour la classification multiclasse\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train_sampled.ravel())\n",
        "y_train_categorical = to_categorical(y_train_encoded)\n",
        "\n",
        "# Mise à jour de la dernière couche Dense pour qu'elle corresponde au nombre de classes\n",
        "#num_classes = y_train_categorical.shape[0]\n",
        "num_classes = y_train_categorical.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "L4HkfswVa_za"
      },
      "outputs": [],
      "source": [
        "# Reshape x_train_sampled et x_test_scaled pour l'entrée du CNN\n",
        "x_train_sampled_cnn = np.expand_dims(x_train_sampled, axis=2)\n",
        "x_test_scaled_cnn = np.expand_dims(x_test, axis=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6wRsdm-41B37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Elodie\\Desktop\\ESIEE\\IA\\PROJET ANNUEL\\ia-for-medecine\\.venv\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\Elodie\\Desktop\\ESIEE\\IA\\PROJET ANNUEL\\ia-for-medecine\\.venv\\lib\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\Elodie\\Desktop\\ESIEE\\IA\\PROJET ANNUEL\\ia-for-medecine\\.venv\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Modèle CNN avec trois couches convolutionnelles\n",
        "cnn_model = Sequential([\n",
        "    # Augmente la taille de l'input si nécessaire ou ajuste les paramètres\n",
        "    Conv1D(128, 3, activation='relu', padding='same', input_shape=(x_train_sampled.shape[1], 1)),\n",
        "    MaxPooling1D(2),\n",
        "    # Ajout d'une seconde couche convolutive avec padding pour conserver la dimension\n",
        "    Conv1D(128, 3, activation='relu', padding='same'),\n",
        "    MaxPooling1D(2),\n",
        "    Conv1D(128, 3, activation='relu', padding='same'),\n",
        "    MaxPooling1D(2),\n",
        "    Flatten(name='flatten_layer'),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilation du modèle avec la métrique correcte\n",
        "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHTTvXu41FCQ",
        "outputId": "2d818196-5f63-434a-f730-8372e2968135"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "WARNING:tensorflow:From c:\\Users\\Elodie\\Desktop\\ESIEE\\IA\\PROJET ANNUEL\\ia-for-medecine\\.venv\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\Elodie\\Desktop\\ESIEE\\IA\\PROJET ANNUEL\\ia-for-medecine\\.venv\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "1128/1128 [==============================] - 6s 4ms/step - loss: 0.5093 - accuracy: 0.7603\n",
            "Epoch 2/20\n",
            "1128/1128 [==============================] - 5s 4ms/step - loss: 0.3847 - accuracy: 0.8201\n",
            "Epoch 3/20\n",
            "1128/1128 [==============================] - 7s 6ms/step - loss: 0.3498 - accuracy: 0.8355\n",
            "Epoch 4/20\n",
            "1128/1128 [==============================] - 8s 7ms/step - loss: 0.3291 - accuracy: 0.8498\n",
            "Epoch 5/20\n",
            "1128/1128 [==============================] - 6s 5ms/step - loss: 0.3083 - accuracy: 0.8604\n",
            "Epoch 6/20\n",
            "1128/1128 [==============================] - 6s 5ms/step - loss: 0.3000 - accuracy: 0.8670\n",
            "Epoch 7/20\n",
            "1128/1128 [==============================] - 6s 5ms/step - loss: 0.2815 - accuracy: 0.8753\n",
            "Epoch 8/20\n",
            "1128/1128 [==============================] - 6s 5ms/step - loss: 0.2693 - accuracy: 0.8811\n",
            "Epoch 9/20\n",
            "1128/1128 [==============================] - 5s 5ms/step - loss: 0.2569 - accuracy: 0.8850\n",
            "Epoch 10/20\n",
            "1128/1128 [==============================] - 5s 5ms/step - loss: 0.2486 - accuracy: 0.8942\n",
            "Epoch 11/20\n",
            "1128/1128 [==============================] - 5s 5ms/step - loss: 0.2343 - accuracy: 0.8975\n",
            "Epoch 12/20\n",
            "1128/1128 [==============================] - 5s 4ms/step - loss: 0.2230 - accuracy: 0.9038\n",
            "Epoch 13/20\n",
            "1128/1128 [==============================] - 5s 5ms/step - loss: 0.2148 - accuracy: 0.9067\n",
            "Epoch 14/20\n",
            "1128/1128 [==============================] - 5s 4ms/step - loss: 0.2056 - accuracy: 0.9113\n",
            "Epoch 15/20\n",
            "1128/1128 [==============================] - 5s 5ms/step - loss: 0.1972 - accuracy: 0.9141\n",
            "Epoch 16/20\n",
            "1128/1128 [==============================] - 6s 5ms/step - loss: 0.1899 - accuracy: 0.9188\n",
            "Epoch 17/20\n",
            "1128/1128 [==============================] - 5s 5ms/step - loss: 0.1782 - accuracy: 0.9210\n",
            "Epoch 18/20\n",
            "1128/1128 [==============================] - 5s 5ms/step - loss: 0.1770 - accuracy: 0.9223\n",
            "Epoch 19/20\n",
            "1128/1128 [==============================] - 8s 7ms/step - loss: 0.1693 - accuracy: 0.9288\n",
            "Epoch 20/20\n",
            "1128/1128 [==============================] - 6s 5ms/step - loss: 0.1578 - accuracy: 0.9322\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x1fe462d2140>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Entraînement du modèle\n",
        "cnn_model.fit(x_train_sampled_cnn, y_train_categorical, epochs=20, batch_size=20, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw1OEllvuvnQ",
        "outputId": "d44f4785-e4a8-4ce9-cb62-a41e4faf5f5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "705/705 [==============================] - 4s 5ms/step - loss: 0.1322 - accuracy: 0.9419\n",
            "Epoch 2/30\n",
            "705/705 [==============================] - 3s 5ms/step - loss: 0.1296 - accuracy: 0.9443\n",
            "Epoch 3/30\n",
            "705/705 [==============================] - 4s 5ms/step - loss: 0.1281 - accuracy: 0.9447\n",
            "Epoch 4/30\n",
            "705/705 [==============================] - 3s 5ms/step - loss: 0.1254 - accuracy: 0.9453\n",
            "Epoch 5/30\n",
            "705/705 [==============================] - 3s 5ms/step - loss: 0.1231 - accuracy: 0.9478\n",
            "Epoch 6/30\n",
            "705/705 [==============================] - 4s 6ms/step - loss: 0.1184 - accuracy: 0.9485\n",
            "Epoch 7/30\n",
            "705/705 [==============================] - 4s 5ms/step - loss: 0.1139 - accuracy: 0.9513\n",
            "Epoch 8/30\n",
            "705/705 [==============================] - 4s 5ms/step - loss: 0.1159 - accuracy: 0.9507\n",
            "Epoch 9/30\n",
            "705/705 [==============================] - 3s 5ms/step - loss: 0.1065 - accuracy: 0.9543\n",
            "Epoch 10/30\n",
            "705/705 [==============================] - 3s 4ms/step - loss: 0.1061 - accuracy: 0.9546\n",
            "Epoch 11/30\n",
            "705/705 [==============================] - 3s 4ms/step - loss: 0.1064 - accuracy: 0.9554\n",
            "Epoch 12/30\n",
            "705/705 [==============================] - 3s 4ms/step - loss: 0.0957 - accuracy: 0.9605\n",
            "Epoch 13/30\n",
            "705/705 [==============================] - 3s 4ms/step - loss: 0.0981 - accuracy: 0.9575\n",
            "Epoch 14/30\n",
            "705/705 [==============================] - 3s 4ms/step - loss: 0.0942 - accuracy: 0.9592\n",
            "Epoch 15/30\n",
            "705/705 [==============================] - 3s 4ms/step - loss: 0.0952 - accuracy: 0.9606\n",
            "Epoch 16/30\n",
            "705/705 [==============================] - 3s 4ms/step - loss: 0.0885 - accuracy: 0.9634\n",
            "Epoch 17/30\n",
            "705/705 [==============================] - 3s 4ms/step - loss: 0.0945 - accuracy: 0.9627\n",
            "Epoch 18/30\n",
            "705/705 [==============================] - 3s 5ms/step - loss: 0.0937 - accuracy: 0.9611\n",
            "Epoch 19/30\n",
            "705/705 [==============================] - 3s 4ms/step - loss: 0.0787 - accuracy: 0.9670\n",
            "Epoch 20/30\n",
            "705/705 [==============================] - 3s 4ms/step - loss: 0.0834 - accuracy: 0.9667\n",
            "Epoch 21/30\n",
            "705/705 [==============================] - 3s 4ms/step - loss: 0.0809 - accuracy: 0.9663\n",
            "Epoch 22/30\n",
            "705/705 [==============================] - 3s 4ms/step - loss: 0.0814 - accuracy: 0.9671\n",
            "Epoch 23/30\n",
            "705/705 [==============================] - 3s 5ms/step - loss: 0.0805 - accuracy: 0.9657\n",
            "Epoch 24/30\n",
            "705/705 [==============================] - 3s 4ms/step - loss: 0.0734 - accuracy: 0.9702\n",
            "Epoch 25/30\n",
            "705/705 [==============================] - 3s 4ms/step - loss: 0.0769 - accuracy: 0.9697\n",
            "Epoch 26/30\n",
            "705/705 [==============================] - 3s 4ms/step - loss: 0.0749 - accuracy: 0.9703\n",
            "Epoch 27/30\n",
            "705/705 [==============================] - 3s 4ms/step - loss: 0.0707 - accuracy: 0.9721\n",
            "Epoch 28/30\n",
            "705/705 [==============================] - 3s 5ms/step - loss: 0.0670 - accuracy: 0.9725\n",
            "Epoch 29/30\n",
            "705/705 [==============================] - 3s 4ms/step - loss: 0.0714 - accuracy: 0.9712\n",
            "Epoch 30/30\n",
            "705/705 [==============================] - 3s 4ms/step - loss: 0.0744 - accuracy: 0.9707\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x1fe47b320b0>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Entraînement du modele avec 30 assages complets de l'ensemble de données d'entraînement &\n",
        "# 32 batch_size (..) données d'entraînement seront divisées en lots de 32 échantillons.\n",
        "# Pr chaque lot, les poids du modèle seront MAJ\n",
        "cnn_model.fit(x_train_sampled_cnn, y_train_categorical, epochs=30, batch_size=32, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn_model.save(models_path + 'cnn_model.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4ODf7T8ePFT"
      },
      "source": [
        "# Traitement CNN 21.05.2024 proposé"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVw6Zw_geFYk",
        "outputId": "17677dfb-9a08-4bed-b23b-c33fc311787e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "705/705 [==============================] - 2s 2ms/step\n",
            "101/101 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# New modèle pour extraire les caractéristiques de la couche Flatten\n",
        "feature_extractor = Model(inputs=cnn_model.input, outputs=cnn_model.get_layer('flatten_layer').output)\n",
        "\n",
        "# extrait les caractéristiques pour les ensembles d'entraînement et de test\n",
        "x_train_sampled_feat_extracted = feature_extractor.predict(x_train_sampled_cnn)\n",
        "x_test_feat_extracted = feature_extractor.predict(x_test_scaled_cnn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_extractor.save(models_path + \"feature_extractor.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzy0AFt0Zx9H",
        "outputId": "8b713c4c-a66d-4259-9963-a69fa85a7e6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "705/705 [==============================] - 2s 2ms/step - loss: 0.0514 - accuracy: 0.9791\n",
            "Accuracy: 0.9790724515914917\n"
          ]
        }
      ],
      "source": [
        "# La méthode score (print_score) n'existe pas pour les objets de type Sequential dans TensorFlow/Keras.\n",
        "# Dans Keras, l'évaluation des modèles se fait généralement avec les méthodes\n",
        "# evaluate ou predict pour obtenir des métriques\n",
        "\n",
        "\n",
        "# Évaluation du modèle\n",
        "loss, accuracy = cnn_model.evaluate(x_train_sampled, y_train_categorical, verbose=1)\n",
        "\n",
        "# Affichage de la précision du modèle\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb28cMdtqqVB"
      },
      "source": [
        "## Features Extraction : LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "FlOmLuugqqVC"
      },
      "outputs": [],
      "source": [
        "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "l7fOusuaqqVC"
      },
      "outputs": [],
      "source": [
        "# lda = LinearDiscriminantAnalysis(n_components=None)\n",
        "# x_train_sampled_feat_extracted = lda.fit_transform(x_train_sampled, y_train_sampled)\n",
        "# x_test_feat_extracted = lda.transform(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OraOy2mliVCq"
      },
      "source": [
        "## Functions print_score, print_accuracy and get_confusion_matrix_and_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "JX4tEVfeqqVD"
      },
      "outputs": [],
      "source": [
        "def print_score(model):\n",
        "    score = model.score(x_train_sampled_feat_extracted, y_train_sampled.ravel())\n",
        "    print(\"Score : \" + str(score))\n",
        "\n",
        "\n",
        "def print_accuracy(y):\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y))\n",
        "\n",
        "\n",
        "def get_confusion_matrix_and_results(y):\n",
        "    # Create confusion matrix\n",
        "    cm = confusion_matrix(y_test, y)\n",
        "    cr = classification_report(y_test, y)\n",
        "\n",
        "    print(cr)\n",
        "    print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk-3GEaxqqVE"
      },
      "source": [
        "## Random Forest Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWahjOyyqqVF",
        "outputId": "ff03c7f9-381c-47d2-c6f2-72c3e53f3f98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score : 0.9999113239336703\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "random_forest = RandomForestClassifier(n_estimators= 20, criterion=\"entropy\", class_weight=\"balanced\")\n",
        "# random_forest.fit(x_train_sampled, y_train_sampled.ravel())\n",
        "random_forest.fit(x_train_sampled_feat_extracted, y_train_sampled.ravel())\n",
        "\n",
        "print_score(random_forest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBWiSHWBqqVG",
        "outputId": "78958406-8f8f-424b-c628-d1bbd3a9d594"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.87      0.86      2500\n",
            "         1.0       0.52      0.51      0.51       692\n",
            "         2.0       0.14      0.18      0.16        11\n",
            "\n",
            "    accuracy                           0.79      3203\n",
            "   macro avg       0.51      0.52      0.51      3203\n",
            "weighted avg       0.79      0.79      0.79      3203\n",
            "\n",
            "[[2166  325    9]\n",
            " [ 339  350    3]\n",
            " [   7    2    2]]\n"
          ]
        }
      ],
      "source": [
        "# Predicting the test set result\n",
        "y_pred = random_forest.predict(x_test_feat_extracted)\n",
        "\n",
        "get_confusion_matrix_and_results(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmHtxQtsqqVH"
      },
      "source": [
        "## Logistic Regression Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WM30c12qqVJ",
        "outputId": "7c316fe0-fcdf-4898-eb02-6f587ffe2fa2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score : 0.981821406402412\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Elodie\\Desktop\\ESIEE\\IA\\PROJET ANNUEL\\ia-for-medecine\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logistic_regression = LogisticRegression(class_weight=\"balanced\")\n",
        "\n",
        "logistic_regression.fit(x_train_sampled_feat_extracted, y_train_sampled.ravel())\n",
        "\n",
        "print_score(logistic_regression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4JAhelyqqVK",
        "outputId": "62ae710e-f4d5-4013-cf85-fe6fff799176"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.85      0.86      2500\n",
            "         1.0       0.50      0.54      0.52       692\n",
            "         2.0       0.15      0.18      0.17        11\n",
            "\n",
            "    accuracy                           0.78      3203\n",
            "   macro avg       0.51      0.52      0.51      3203\n",
            "weighted avg       0.78      0.78      0.78      3203\n",
            "\n",
            "[[2113  377   10]\n",
            " [ 318  373    1]\n",
            " [   8    1    2]]\n"
          ]
        }
      ],
      "source": [
        "# Prediction on the test set\n",
        "y_pred = logistic_regression.predict(x_test_feat_extracted)\n",
        "\n",
        "get_confusion_matrix_and_results(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2tnEavJqqVL"
      },
      "source": [
        "## K-Nearest Neighbours (KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXQ__lT-qqVM",
        "outputId": "eddd8f00-dd1c-4a2e-f69f-054b4af487b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score : 0.9469717123348408\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=20, weights=\"uniform\")\n",
        "\n",
        "knn.fit(x_train_sampled_feat_extracted, y_train_sampled.ravel())\n",
        "\n",
        "\n",
        "print_score(knn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghYnVWGEqqVN",
        "outputId": "7cd475e7-1f6f-49d5-94da-7e2e64fcc139"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.80      0.84      2500\n",
            "         1.0       0.48      0.65      0.55       692\n",
            "         2.0       0.15      0.27      0.19        11\n",
            "\n",
            "    accuracy                           0.76      3203\n",
            "   macro avg       0.51      0.57      0.53      3203\n",
            "weighted avg       0.80      0.76      0.78      3203\n",
            "\n",
            "[[1995  490   15]\n",
            " [ 242  448    2]\n",
            " [   6    2    3]]\n"
          ]
        }
      ],
      "source": [
        "# Prediction on the test set\n",
        "y_pred = knn.predict(x_test_feat_extracted)\n",
        "\n",
        "\n",
        "get_confusion_matrix_and_results(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAPMSL5MqqVO"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFStnhhlqqVP",
        "outputId": "6c9739f8-b97a-42de-eaae-f01ade7fddf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score : 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "decision_tree = DecisionTreeClassifier(class_weight=\"balanced\")\n",
        "\n",
        "decision_tree.fit(x_train_sampled_feat_extracted, y_train_sampled)\n",
        "\n",
        "print_score(decision_tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkrzA6ftqqVQ",
        "outputId": "c8499f48-0f11-444f-bb5c-0f4d8b67ce23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.81      0.83      2500\n",
            "         1.0       0.44      0.51      0.47       692\n",
            "         2.0       0.05      0.09      0.07        11\n",
            "\n",
            "    accuracy                           0.75      3203\n",
            "   macro avg       0.45      0.47      0.46      3203\n",
            "weighted avg       0.76      0.75      0.75      3203\n",
            "\n",
            "[[2033  452   15]\n",
            " [ 335  354    3]\n",
            " [   8    2    1]]\n"
          ]
        }
      ],
      "source": [
        "y_pred = decision_tree.predict(x_test_feat_extracted)\n",
        "\n",
        "\n",
        "get_confusion_matrix_and_results(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQrxGl_BqqVQ"
      },
      "source": [
        "# Best classifier selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7B7MEUMsqqVS",
        "outputId": "17fe5344-a8c7-4817-fb1e-a652ad2479bc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Elodie\\Desktop\\ESIEE\\IA\\PROJET ANNUEL\\ia-for-medecine\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score : 0.9982264786734061\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "voting_clf = VotingClassifier(estimators=[('rf', random_forest), ('knn', knn), ('arbre decisionnel', decision_tree), ('logistic regression', logistic_regression)], voting='soft')\n",
        "voting_clf.fit(x_train_sampled_feat_extracted, y_train_sampled)\n",
        "\n",
        "print_score(voting_clf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vLmktr-qqVT",
        "outputId": "b4016ec7-3c75-4414-a64e-7705fc385203"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.85      0.86      2500\n",
            "         1.0       0.51      0.55      0.53       692\n",
            "         2.0       0.15      0.18      0.17        11\n",
            "\n",
            "    accuracy                           0.78      3203\n",
            "   macro avg       0.51      0.53      0.52      3203\n",
            "weighted avg       0.79      0.78      0.79      3203\n",
            "\n",
            "[[2123  368    9]\n",
            " [ 307  383    2]\n",
            " [   8    1    2]]\n"
          ]
        }
      ],
      "source": [
        "y_pred = voting_clf.predict(x_test_feat_extracted)\n",
        "\n",
        "get_confusion_matrix_and_results(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tfykxosqqVT"
      },
      "source": [
        "# Boosting\n",
        "We are going to create a strong model with the Boosting technique using our previous simple models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "yx3UUD1NqqVU"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "base_models = [\n",
        "    random_forest,\n",
        "    logistic_regression,\n",
        "    decision_tree\n",
        "]\n",
        "\n",
        "model_names = [\n",
        "    \"random_forest\",\n",
        "    \"logistic_regression\",\n",
        "    \"decision_tree\"\n",
        "]\n",
        "\n",
        "adaboost_classifiers = []\n",
        "for base_model in base_models:\n",
        "    adaboost_classifier = AdaBoostClassifier(base_model, n_estimators=50, learning_rate=1)\n",
        "    adaboost_classifiers.append(adaboost_classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKr6GaJ2qqVW",
        "outputId": "6eaf8746-b79a-42e0-9754-aa4897f2b3d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Base model used : RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
            "                       n_estimators=20)\n",
            "Score : 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.86      0.87      2500\n",
            "         1.0       0.54      0.56      0.55       692\n",
            "         2.0       0.17      0.18      0.17        11\n",
            "\n",
            "    accuracy                           0.80      3203\n",
            "   macro avg       0.53      0.54      0.53      3203\n",
            "weighted avg       0.80      0.80      0.80      3203\n",
            "\n",
            "[[2161  331    8]\n",
            " [ 301  389    2]\n",
            " [   8    1    2]]\n",
            "\n",
            "Base model used : LogisticRegression(class_weight='balanced')\n",
            "Score : 0.9556619668351511\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.85      0.88      0.87      2500\n",
            "         1.0       0.53      0.47      0.50       692\n",
            "         2.0       0.29      0.18      0.22        11\n",
            "\n",
            "    accuracy                           0.79      3203\n",
            "   macro avg       0.56      0.51      0.53      3203\n",
            "weighted avg       0.78      0.79      0.79      3203\n",
            "\n",
            "[[2207  289    4]\n",
            " [ 367  324    1]\n",
            " [   8    1    2]]\n",
            "\n",
            "Base model used : DecisionTreeClassifier(class_weight='balanced')\n",
            "Score : 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.85      0.81      0.83      2500\n",
            "         1.0       0.43      0.50      0.46       692\n",
            "         2.0       0.05      0.09      0.07        11\n",
            "\n",
            "    accuracy                           0.74      3203\n",
            "   macro avg       0.44      0.47      0.45      3203\n",
            "weighted avg       0.76      0.74      0.75      3203\n",
            "\n",
            "[[2025  462   13]\n",
            " [ 343  344    5]\n",
            " [   7    3    1]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate each AdaBoost classifier\n",
        "for i, adaboost_classifier in enumerate(adaboost_classifiers):\n",
        "    print(\"Base model used :\", base_models[i])\n",
        "\n",
        "    # Train the AdaBoost classifier\n",
        "    adaboost_classifier.fit(x_train_sampled_feat_extracted, y_train_sampled)\n",
        "\n",
        "    joblib.dump(adaboost_classifier, models_path + model_names[i] + \"_model.joblib\")\n",
        "\n",
        "    print_score(adaboost_classifier)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred = adaboost_classifier.predict(x_test_feat_extracted)\n",
        "\n",
        "    get_confusion_matrix_and_results(y_pred)\n",
        "\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test loading models and make predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 89ms/step\n",
            "[[ 387.33035  198.19728    0.      ...    0.         0.         0.     ]\n",
            " [1132.1938     0.         0.      ...    0.         0.         0.     ]\n",
            " [2092.4973     0.         0.      ...    0.         0.         0.     ]\n",
            " ...\n",
            " [  33.45929 1777.031      0.      ...    0.         0.         0.     ]\n",
            " [   0.       654.44885    0.      ...    0.         0.         0.     ]\n",
            " [   0.         0.         0.      ...    0.         0.         0.     ]]\n"
          ]
        }
      ],
      "source": [
        "test_data = pd.read_csv(ressources_path + \"test.txt\", header=None, delimiter=\" \")\n",
        "\n",
        "\n",
        "test_feature_extractor = load_model(models_path + \"feature_extractor.keras\")\n",
        "\n",
        "extracted_data = test_feature_extractor.predict(test_data)\n",
        "\n",
        "print(extracted_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "test_classifier_model = joblib.load(models_path + \"random_forest_model.joblib\")\n",
        "\n",
        "pred = test_classifier_model.predict(extracted_data)\n",
        "print(pred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
