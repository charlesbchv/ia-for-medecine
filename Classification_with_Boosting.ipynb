{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLaebpXyqqUr"
      },
      "source": [
        "# Classic classification algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDqYjKwDqqUw"
      },
      "source": [
        "We are going to classify our datasets using multiple classification algorithms and evaluate their performances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTL6llluqqUy",
        "outputId": "5f7f549b-6113-4e7e-c536-0a5d2301d87b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scikit-learn is not installed. Installing...\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "imblearn is already installed.\n",
            "deslib is not installed. Installing...\n",
            "Collecting deslib\n",
            "  Downloading DESlib-0.3.7-py3-none-any.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.6/172.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from deslib) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from deslib) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from deslib) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->deslib) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->deslib) (3.5.0)\n",
            "Installing collected packages: deslib\n",
            "Successfully installed deslib-0.3.7\n"
          ]
        }
      ],
      "source": [
        "# Packages to install\n",
        "packages_to_install = ['scikit-learn', 'imblearn', 'deslib']\n",
        "\n",
        "# Check if they are already installed\n",
        "import importlib\n",
        "for package in packages_to_install:\n",
        "    try:\n",
        "        importlib.import_module(package)\n",
        "        print(f\"{package} is already installed.\")\n",
        "    except ImportError:\n",
        "        print(f\"{package} is not installed. Installing...\")\n",
        "        !pip install {package}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rznrNVCXqqU1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XZ0f-MHqqU2"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "Iwxcot_nqqU3",
        "outputId": "d769a92c-c321-49aa-890b-a4955963c2b7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>12809.000000</td>\n",
              "      <td>12809.000000</td>\n",
              "      <td>12809.000000</td>\n",
              "      <td>12809.000000</td>\n",
              "      <td>12809.000000</td>\n",
              "      <td>12809.000000</td>\n",
              "      <td>12809.000000</td>\n",
              "      <td>12809.000000</td>\n",
              "      <td>12809.000000</td>\n",
              "      <td>12809.000000</td>\n",
              "      <td>12809.000000</td>\n",
              "      <td>12809.000000</td>\n",
              "      <td>12809.000000</td>\n",
              "      <td>12809.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.715800</td>\n",
              "      <td>105.179340</td>\n",
              "      <td>151.438104</td>\n",
              "      <td>550.188281</td>\n",
              "      <td>1858.821366</td>\n",
              "      <td>0.639516</td>\n",
              "      <td>0.606294</td>\n",
              "      <td>13.894588</td>\n",
              "      <td>151.443231</td>\n",
              "      <td>149.896051</td>\n",
              "      <td>400.836349</td>\n",
              "      <td>1220.861916</td>\n",
              "      <td>0.639516</td>\n",
              "      <td>0.726532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>13.661444</td>\n",
              "      <td>118.380416</td>\n",
              "      <td>198.978664</td>\n",
              "      <td>596.648195</td>\n",
              "      <td>4357.460170</td>\n",
              "      <td>0.298755</td>\n",
              "      <td>0.355149</td>\n",
              "      <td>25.014059</td>\n",
              "      <td>184.578246</td>\n",
              "      <td>182.014356</td>\n",
              "      <td>427.817220</td>\n",
              "      <td>2481.003246</td>\n",
              "      <td>0.298755</td>\n",
              "      <td>0.402590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.004030</td>\n",
              "      <td>0.497232</td>\n",
              "      <td>1.136887</td>\n",
              "      <td>1.550758</td>\n",
              "      <td>2.000634</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009388</td>\n",
              "      <td>0.008162</td>\n",
              "      <td>1.076040</td>\n",
              "      <td>0.955428</td>\n",
              "      <td>3.392103</td>\n",
              "      <td>7.449574</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.651308</td>\n",
              "      <td>28.135965</td>\n",
              "      <td>36.205070</td>\n",
              "      <td>160.794149</td>\n",
              "      <td>572.195981</td>\n",
              "      <td>0.407475</td>\n",
              "      <td>0.324020</td>\n",
              "      <td>0.593510</td>\n",
              "      <td>22.236411</td>\n",
              "      <td>36.182643</td>\n",
              "      <td>125.101548</td>\n",
              "      <td>436.947264</td>\n",
              "      <td>0.407475</td>\n",
              "      <td>0.373920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.563679</td>\n",
              "      <td>73.496119</td>\n",
              "      <td>79.066449</td>\n",
              "      <td>341.937147</td>\n",
              "      <td>1092.008474</td>\n",
              "      <td>0.664512</td>\n",
              "      <td>0.461491</td>\n",
              "      <td>3.255613</td>\n",
              "      <td>83.524212</td>\n",
              "      <td>84.391739</td>\n",
              "      <td>255.453341</td>\n",
              "      <td>768.756167</td>\n",
              "      <td>0.664512</td>\n",
              "      <td>0.567023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>9.841018</td>\n",
              "      <td>145.229559</td>\n",
              "      <td>183.952667</td>\n",
              "      <td>722.194942</td>\n",
              "      <td>2030.703113</td>\n",
              "      <td>0.859797</td>\n",
              "      <td>0.844648</td>\n",
              "      <td>17.586211</td>\n",
              "      <td>223.050740</td>\n",
              "      <td>191.915684</td>\n",
              "      <td>518.186018</td>\n",
              "      <td>1335.167249</td>\n",
              "      <td>0.859797</td>\n",
              "      <td>1.063422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>513.804645</td>\n",
              "      <td>4126.791150</td>\n",
              "      <td>3471.703620</td>\n",
              "      <td>6547.571997</td>\n",
              "      <td>304245.165000</td>\n",
              "      <td>1.932471</td>\n",
              "      <td>1.933941</td>\n",
              "      <td>540.411313</td>\n",
              "      <td>3139.233639</td>\n",
              "      <td>2126.014583</td>\n",
              "      <td>6557.959843</td>\n",
              "      <td>92455.135460</td>\n",
              "      <td>1.932471</td>\n",
              "      <td>1.990678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0             1             2             3              4   \\\n",
              "count  12809.000000  12809.000000  12809.000000  12809.000000   12809.000000   \n",
              "mean       7.715800    105.179340    151.438104    550.188281    1858.821366   \n",
              "std       13.661444    118.380416    198.978664    596.648195    4357.460170   \n",
              "min        0.004030      0.497232      1.136887      1.550758       2.000634   \n",
              "25%        0.651308     28.135965     36.205070    160.794149     572.195981   \n",
              "50%        2.563679     73.496119     79.066449    341.937147    1092.008474   \n",
              "75%        9.841018    145.229559    183.952667    722.194942    2030.703113   \n",
              "max      513.804645   4126.791150   3471.703620   6547.571997  304245.165000   \n",
              "\n",
              "                 5             6             8             9             10  \\\n",
              "count  12809.000000  12809.000000  12809.000000  12809.000000  12809.000000   \n",
              "mean       0.639516      0.606294     13.894588    151.443231    149.896051   \n",
              "std        0.298755      0.355149     25.014059    184.578246    182.014356   \n",
              "min        0.000000      0.009388      0.008162      1.076040      0.955428   \n",
              "25%        0.407475      0.324020      0.593510     22.236411     36.182643   \n",
              "50%        0.664512      0.461491      3.255613     83.524212     84.391739   \n",
              "75%        0.859797      0.844648     17.586211    223.050740    191.915684   \n",
              "max        1.932471      1.933941    540.411313   3139.233639   2126.014583   \n",
              "\n",
              "                 11            12            13            14  \n",
              "count  12809.000000  12809.000000  12809.000000  12809.000000  \n",
              "mean     400.836349   1220.861916      0.639516      0.726532  \n",
              "std      427.817220   2481.003246      0.298755      0.402590  \n",
              "min        3.392103      7.449574      0.000000      0.006647  \n",
              "25%      125.101548    436.947264      0.407475      0.373920  \n",
              "50%      255.453341    768.756167      0.664512      0.567023  \n",
              "75%      518.186018   1335.167249      0.859797      1.063422  \n",
              "max     6557.959843  92455.135460      1.932471      1.990678  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x1 = pd.read_csv(\"./Ressources/Datasets/stand_norm_e1.txt\", header=None, delimiter=\" \")\n",
        "x2 = pd.read_csv(\"./Ressources/Datasets/stand_norm_e2.txt\", header=None, delimiter=\" \", names=[8, 9, 10, 11, 12, 13, 14])\n",
        "y = pd.read_csv(\"./Ressources/Datasets/y2_e1.txt\", header=None, delimiter=\" \", names=[\"label\"])\n",
        "x = pd.concat([x1, x2], axis=1)\n",
        "x = x[1:]\n",
        "y = y[1:]\n",
        "\n",
        "x.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UC9ApHTZqqU5"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset into training and test set.\n",
        "x_train, x_test, y_train, y_test = train_test_split(x.values, y.values, test_size = 0.25, random_state=0)\n",
        "\n",
        "# Feature Scaling\n",
        "# Adjust the mean to 0 and the standard deviation to 1\n",
        "st_x = StandardScaler()\n",
        "x_train = st_x.fit_transform(x_train)\n",
        "x_test = st_x.transform(x_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HeNvu29LqqU6"
      },
      "outputs": [],
      "source": [
        "# Oversample to have same number of samples of each class\n",
        "smote = SMOTE()\n",
        "x_train_sampled, y_train_sampled = smote.fit_resample(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKfDJ2m4qqU8"
      },
      "source": [
        "## Feature extraction : CNN\n",
        "We are going to extract features from the datasets using the CNN method, knowing that it has the best performances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lavZ6T-GqqU-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Vérification et reformattage de y_train_sampled pour la classification multiclasse\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train_sampled.ravel())\n",
        "y_train_categorical = to_categorical(y_train_encoded)\n",
        "\n",
        "# Mise à jour de la dernière couche Dense pour qu'elle corresponde au nombre de classes\n",
        "#num_classes = y_train_categorical.shape[0]\n",
        "num_classes = y_train_categorical.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "6wRsdm-41B37"
      },
      "outputs": [],
      "source": [
        "cnn_model = Sequential([\n",
        "    # Augmente la taille de l'input si nécessaire ou ajuster les paramètres\n",
        "    Conv1D(128, 3, activation='relu', padding='same', input_shape=(x_train_sampled.shape[1], 1)),\n",
        "    MaxPooling1D(2),\n",
        "    # Ajout d'une seconde couche convolutive avec padding pour conserver la dimension\n",
        "    Conv1D(128, 3, activation='relu', padding='same'),\n",
        "    MaxPooling1D(2),\n",
        "    Flatten(),\n",
        "    Dense(100, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilation du modèle avec la métrique correcte\n",
        "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHTTvXu41FCQ",
        "outputId": "14816042-8054-4f36-9b8f-a82c6d5b3448"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1127/1127 [==============================] - 15s 11ms/step - loss: 0.5199 - accuracy: 0.7650\n",
            "Epoch 2/20\n",
            "1127/1127 [==============================] - 8s 7ms/step - loss: 0.3967 - accuracy: 0.8113\n",
            "Epoch 3/20\n",
            "1127/1127 [==============================] - 7s 6ms/step - loss: 0.3672 - accuracy: 0.8261\n",
            "Epoch 4/20\n",
            "1127/1127 [==============================] - 8s 7ms/step - loss: 0.3478 - accuracy: 0.8356\n",
            "Epoch 5/20\n",
            "1127/1127 [==============================] - 6s 6ms/step - loss: 0.3270 - accuracy: 0.8467\n",
            "Epoch 6/20\n",
            "1127/1127 [==============================] - 10s 9ms/step - loss: 0.3182 - accuracy: 0.8537\n",
            "Epoch 7/20\n",
            "1127/1127 [==============================] - 8s 7ms/step - loss: 0.3164 - accuracy: 0.8524\n",
            "Epoch 8/20\n",
            "1127/1127 [==============================] - 7s 6ms/step - loss: 0.3050 - accuracy: 0.8597\n",
            "Epoch 9/20\n",
            "1127/1127 [==============================] - 8s 7ms/step - loss: 0.2968 - accuracy: 0.8645\n",
            "Epoch 10/20\n",
            "1127/1127 [==============================] - 7s 6ms/step - loss: 0.2893 - accuracy: 0.8679\n",
            "Epoch 11/20\n",
            "1127/1127 [==============================] - 8s 7ms/step - loss: 0.2841 - accuracy: 0.8732\n",
            "Epoch 12/20\n",
            "1127/1127 [==============================] - 7s 6ms/step - loss: 0.2760 - accuracy: 0.8748\n",
            "Epoch 13/20\n",
            "1127/1127 [==============================] - 8s 7ms/step - loss: 0.2725 - accuracy: 0.8793\n",
            "Epoch 14/20\n",
            "1127/1127 [==============================] - 7s 6ms/step - loss: 0.2644 - accuracy: 0.8805\n",
            "Epoch 15/20\n",
            "1127/1127 [==============================] - 8s 7ms/step - loss: 0.2585 - accuracy: 0.8863\n",
            "Epoch 16/20\n",
            "1127/1127 [==============================] - 7s 6ms/step - loss: 0.2535 - accuracy: 0.8879\n",
            "Epoch 17/20\n",
            "1127/1127 [==============================] - 8s 7ms/step - loss: 0.2517 - accuracy: 0.8882\n",
            "Epoch 18/20\n",
            "1127/1127 [==============================] - 7s 6ms/step - loss: 0.2504 - accuracy: 0.8879\n",
            "Epoch 19/20\n",
            "1127/1127 [==============================] - 8s 7ms/step - loss: 0.2391 - accuracy: 0.8941\n",
            "Epoch 20/20\n",
            "1127/1127 [==============================] - 7s 6ms/step - loss: 0.2362 - accuracy: 0.8934\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a842c0b0c40>"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Entraînement du modèle\n",
        "cnn_model.fit(x_train_sampled, y_train_categorical, epochs=20, batch_size=20, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHXsgADf1MKP",
        "outputId": "9e2bff09-3334-4386-be60-9dcfd45d0a18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "704/704 [==============================] - 2s 3ms/step - loss: 0.2004 - accuracy: 0.9116\n",
            "Accuracy: 0.9116498231887817\n"
          ]
        }
      ],
      "source": [
        "# La méthode score (print_score) n'existe pas pour les objets de type Sequential dans TensorFlow/Keras.\n",
        "# Dans Keras, l'évaluation des modèles se fait généralement avec les méthodes\n",
        "# evaluate ou predict pour obtenir des métriques\n",
        "\n",
        "\n",
        "# Évaluation du modèle\n",
        "loss, accuracy = cnn_model.evaluate(x_train_sampled, y_train_categorical, verbose=1)\n",
        "\n",
        "# Affichage de la précision du modèle\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb28cMdtqqVB"
      },
      "source": [
        "## Features Extraction : LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "FlOmLuugqqVC"
      },
      "outputs": [],
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "l7fOusuaqqVC"
      },
      "outputs": [],
      "source": [
        "lda = LinearDiscriminantAnalysis(n_components=None)\n",
        "x_train_sampled_feat_extracted = lda.fit_transform(x_train_sampled, y_train_sampled)\n",
        "x_test_feat_extracted = lda.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "JX4tEVfeqqVD"
      },
      "outputs": [],
      "source": [
        "def print_score(model):\n",
        "    score = model.score(x_train_sampled_feat_extracted, y_train_sampled.ravel())\n",
        "    print(\"Score : \" + str(score))\n",
        "\n",
        "\n",
        "def print_accuracy(y):\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y))\n",
        "\n",
        "\n",
        "def get_confusion_matrix_and_results(y):\n",
        "    # Create confusion matrix\n",
        "    cm = confusion_matrix(y_test, y)\n",
        "    cr = classification_report(y_test, y)\n",
        "\n",
        "    print(cr)\n",
        "    print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk-3GEaxqqVE"
      },
      "source": [
        "## Random Forest Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "If0e6jB9qqVF"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWahjOyyqqVF",
        "outputId": "c6b621a5-bc2c-49f9-d466-6b1724425008"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score : 0.9946279524063222\n"
          ]
        }
      ],
      "source": [
        "random_forest = RandomForestClassifier(n_estimators= 20, criterion=\"entropy\", class_weight=\"balanced\")\n",
        "# random_forest.fit(x_train_sampled, y_train_sampled.ravel())\n",
        "random_forest.fit(x_train_sampled_feat_extracted, y_train_sampled.ravel())\n",
        "\n",
        "print_score(random_forest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBWiSHWBqqVG",
        "outputId": "300f73f6-0caa-48ec-d9a0-01a1d27fdc54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.85      0.63      0.72      2511\n",
            "         1.0       0.29      0.45      0.35       682\n",
            "         2.0       0.00      0.10      0.01        10\n",
            "\n",
            "    accuracy                           0.59      3203\n",
            "   macro avg       0.38      0.39      0.36      3203\n",
            "weighted avg       0.73      0.59      0.64      3203\n",
            "\n",
            "[[1578  727  206]\n",
            " [ 274  304  104]\n",
            " [   6    3    1]]\n"
          ]
        }
      ],
      "source": [
        "# Predicting the test set result\n",
        "y_pred = random_forest.predict(x_test_feat_extracted)\n",
        "\n",
        "get_confusion_matrix_and_results(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmHtxQtsqqVH"
      },
      "source": [
        "## Logistic Regression Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "i5JggEIxqqVI"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WM30c12qqVJ",
        "outputId": "a460237b-5936-4616-b154-7745b213408d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score : 0.5879950275261943\n"
          ]
        }
      ],
      "source": [
        "logistic_regression = LogisticRegression(class_weight=\"balanced\")\n",
        "\n",
        "logistic_regression.fit(x_train_sampled_feat_extracted, y_train_sampled.ravel())\n",
        "\n",
        "print_score(logistic_regression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4JAhelyqqVK",
        "outputId": "44a6cfd9-b08c-4f8a-b866-2511fb96e5fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.65      0.75      2511\n",
            "         1.0       0.34      0.40      0.37       682\n",
            "         2.0       0.01      0.30      0.01        10\n",
            "\n",
            "    accuracy                           0.60      3203\n",
            "   macro avg       0.41      0.45      0.38      3203\n",
            "weighted avg       0.76      0.60      0.67      3203\n",
            "\n",
            "[[1644  531  336]\n",
            " [ 215  272  195]\n",
            " [   5    2    3]]\n"
          ]
        }
      ],
      "source": [
        "# Prediction on the test set\n",
        "y_pred = logistic_regression.predict(x_test_feat_extracted)\n",
        "\n",
        "get_confusion_matrix_and_results(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2tnEavJqqVL"
      },
      "source": [
        "## K-Nearest Neighbours (KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "ykSCBnmDqqVM"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXQ__lT-qqVM",
        "outputId": "938dca2d-47f7-4bc2-b057-b50a049c3a20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score : 0.7187444503640561\n"
          ]
        }
      ],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=20, weights=\"uniform\")\n",
        "\n",
        "knn.fit(x_train_sampled_feat_extracted, y_train_sampled.ravel())\n",
        "\n",
        "\n",
        "print_score(knn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghYnVWGEqqVN",
        "outputId": "4c0f5550-4cfc-4142-f888-753b66e96dac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.65      0.75      2511\n",
            "         1.0       0.34      0.45      0.39       682\n",
            "         2.0       0.00      0.10      0.00        10\n",
            "\n",
            "    accuracy                           0.61      3203\n",
            "   macro avg       0.41      0.40      0.38      3203\n",
            "weighted avg       0.76      0.61      0.67      3203\n",
            "\n",
            "[[1630  593  288]\n",
            " [ 223  310  149]\n",
            " [   6    3    1]]\n"
          ]
        }
      ],
      "source": [
        "# Prediction on the test set\n",
        "y_pred = knn.predict(x_test_feat_extracted)\n",
        "\n",
        "\n",
        "get_confusion_matrix_and_results(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAPMSL5MqqVO"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "QxXi9JZrqqVO"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFStnhhlqqVP",
        "outputId": "3ea90ca9-196e-406c-9494-ca2b6a9f8974"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score : 1.0\n"
          ]
        }
      ],
      "source": [
        "decision_tree = DecisionTreeClassifier(class_weight=\"balanced\")\n",
        "\n",
        "decision_tree.fit(x_train_sampled_feat_extracted, y_train_sampled)\n",
        "\n",
        "print_score(decision_tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkrzA6ftqqVQ",
        "outputId": "57b10615-e028-4ecd-aa23-6e319f978539"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.57      0.68      2511\n",
            "         1.0       0.25      0.45      0.32       682\n",
            "         2.0       0.00      0.10      0.01        10\n",
            "\n",
            "    accuracy                           0.54      3203\n",
            "   macro avg       0.36      0.37      0.34      3203\n",
            "weighted avg       0.71      0.54      0.60      3203\n",
            "\n",
            "[[1439  893  179]\n",
            " [ 281  304   97]\n",
            " [   6    3    1]]\n"
          ]
        }
      ],
      "source": [
        "y_pred = decision_tree.predict(x_test_feat_extracted)\n",
        "\n",
        "\n",
        "get_confusion_matrix_and_results(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQrxGl_BqqVQ"
      },
      "source": [
        "# Best classifier selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "Reaq7SvmqqVR"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import VotingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7B7MEUMsqqVS",
        "outputId": "bff08ed4-3ab8-4c72-9fe5-0067f5abd0d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score : 0.9946279524063222\n"
          ]
        }
      ],
      "source": [
        "voting_clf = VotingClassifier(estimators=[('rf', random_forest), ('knn', knn), ('arbre decisionnel', decision_tree), ('logistic regression', logistic_regression)], voting='soft')\n",
        "voting_clf.fit(x_train_sampled_feat_extracted, y_train_sampled)\n",
        "\n",
        "print_score(voting_clf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vLmktr-qqVT",
        "outputId": "3d88c737-3409-4de8-cc27-aaa0d51f6359"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.85      0.62      0.72      2511\n",
            "         1.0       0.29      0.45      0.35       682\n",
            "         2.0       0.00      0.10      0.01        10\n",
            "\n",
            "    accuracy                           0.58      3203\n",
            "   macro avg       0.38      0.39      0.36      3203\n",
            "weighted avg       0.73      0.58      0.64      3203\n",
            "\n",
            "[[1550  762  199]\n",
            " [ 265  308  109]\n",
            " [   6    3    1]]\n"
          ]
        }
      ],
      "source": [
        "y_pred = voting_clf.predict(x_test_feat_extracted)\n",
        "\n",
        "get_confusion_matrix_and_results(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tfykxosqqVT"
      },
      "source": [
        "# Boosting\n",
        "We are going to create a strong model with the Boosting technique using our previous simple models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "4PoGWqBHqqVU"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "yx3UUD1NqqVU"
      },
      "outputs": [],
      "source": [
        "base_models = [\n",
        "    random_forest,\n",
        "    logistic_regression,\n",
        "    decision_tree\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "jeVVE8tGqqVV"
      },
      "outputs": [],
      "source": [
        "adaboost_classifiers = []\n",
        "for base_model in base_models:\n",
        "    adaboost_classifier = AdaBoostClassifier(base_model, n_estimators=50, learning_rate=1)\n",
        "    adaboost_classifiers.append(adaboost_classifier)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKr6GaJ2qqVW",
        "outputId": "87a3e344-6dd7-428b-ecfa-e0dda443e86e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Base model used : RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
            "                       n_estimators=20)\n",
            "Score : 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.62      0.72      2511\n",
            "         1.0       0.29      0.45      0.36       682\n",
            "         2.0       0.00      0.10      0.01        10\n",
            "\n",
            "    accuracy                           0.58      3203\n",
            "   macro avg       0.38      0.39      0.36      3203\n",
            "weighted avg       0.73      0.58      0.64      3203\n",
            "\n",
            "[[1562  733  216]\n",
            " [ 256  306  120]\n",
            " [   8    1    1]]\n",
            "\n",
            "Base model used : LogisticRegression(class_weight='balanced')\n",
            "Score : 0.5763185935002664\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.66      0.76      2511\n",
            "         1.0       0.34      0.36      0.35       682\n",
            "         2.0       0.01      0.30      0.01        10\n",
            "\n",
            "    accuracy                           0.60      3203\n",
            "   macro avg       0.41      0.44      0.37      3203\n",
            "weighted avg       0.76      0.60      0.67      3203\n",
            "\n",
            "[[1666  474  371]\n",
            " [ 218  246  218]\n",
            " [   5    2    3]]\n",
            "\n",
            "Base model used : DecisionTreeClassifier(class_weight='balanced')\n",
            "Score : 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.83      0.57      0.67      2511\n",
            "         1.0       0.25      0.44      0.32       682\n",
            "         2.0       0.00      0.10      0.01        10\n",
            "\n",
            "    accuracy                           0.54      3203\n",
            "   macro avg       0.36      0.37      0.33      3203\n",
            "weighted avg       0.71      0.54      0.60      3203\n",
            "\n",
            "[[1423  904  184]\n",
            " [ 281  303   98]\n",
            " [   6    3    1]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate each AdaBoost classifier\n",
        "for i, adaboost_classifier in enumerate(adaboost_classifiers):\n",
        "    print(\"Base model used :\", base_models[i])\n",
        "\n",
        "    # Train the AdaBoost classifier\n",
        "    adaboost_classifier.fit(x_train_sampled_feat_extracted, y_train_sampled)\n",
        "\n",
        "    print_score(adaboost_classifier)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred = adaboost_classifier.predict(x_test_feat_extracted)\n",
        "\n",
        "    get_confusion_matrix_and_results(y_pred)\n",
        "\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUtbIoWfqqVW"
      },
      "source": [
        "## DESlib library\n",
        "We are using the DESlib library to select the best classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3lBx6TnqqVW"
      },
      "outputs": [],
      "source": [
        "# from deslib.des.des_clustering import DESClustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrmpCoNbqqVX"
      },
      "outputs": [],
      "source": [
        "# des = DESClustering(pool_classifiers=[knn, random_forest, decision_tree])\n",
        "# des.fit(x_train_sampled_feat_extracted, y_train_sampled.ravel())\n",
        "\n",
        "# print_score(des)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NwDh3fhqqVX"
      },
      "outputs": [],
      "source": [
        "# y_pred = des.predict(x_test_feat_extracted)\n",
        "\n",
        "\n",
        "# get_confusion_matrix_and_results(y_pred)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
